{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMHMYaoW1wL2+f6FLvoYoV4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["### IF YOU ARE USING COLAB, UNCOMMENT AND RUN THIS BLOCK FIRST ###\n","\n","# Mount google drive to allow access to your files\n","from google.colab import drive\n","drive.mount('/content/drive')\n","drive_folder = '/content/drive/MyDrive'\n","# Ajust this line to be the assignment1 folder in your google drive\n","notebook_folder = drive_folder + '/neuralEvolution'\n","%cd {notebook_folder}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sGU156ElI6W0","executionInfo":{"status":"ok","timestamp":1729219688733,"user_tz":240,"elapsed":1043,"user":{"displayName":"Rahul shah","userId":"08697968008726674087"}},"outputId":"830736f3-b8a6-446c-ba44-b1b55bfea0e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/neuralEvolution\n"]}]},{"cell_type":"code","source":["%cd ../../"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oVLzs35dJP-Z","executionInfo":{"status":"ok","timestamp":1729219864867,"user_tz":240,"elapsed":142,"user":{"displayName":"Rahul shah","userId":"08697968008726674087"}},"outputId":"903153f3-bdf7-469c-ecac-674ca89c4686"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FWR8kQ9HIsXU","executionInfo":{"status":"ok","timestamp":1729219655170,"user_tz":240,"elapsed":154,"user":{"displayName":"Rahul shah","userId":"08697968008726674087"}},"outputId":"50ffe1d5-ec44-43f7-c790-2c370335d754"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: './neuralEvolution/datasets'\n","/content/drive/MyDrive/neuralEvolution\n","bash: get_datasets.sh: No such file or directory\n","/content/drive\n"]}],"source":["%cd ./neuralEvolution/datasets\n","!bash get_datasets.sh\n","%cd ../../"]},{"cell_type":"code","source":["!pip install deap keras tensorflow matplotlib"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q8nmsHvRir72","executionInfo":{"status":"ok","timestamp":1729219980462,"user_tz":240,"elapsed":4364,"user":{"displayName":"Rahul shah","userId":"08697968008726674087"}},"outputId":"f054d919-d342-4ec3-f605-5733ed0f3435"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting deap\n","  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deap) (1.26.4)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.2)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.0)\n","Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.1)\n","Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: deap\n","Successfully installed deap-1.4.1\n"]}]},{"cell_type":"code","source":["import random\n","import numpy as np\n","from deap import base, creator, tools, algorithms\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n","from keras.datasets import cifar10\n","from keras.utils import to_categorical\n","from tensorflow.keras.optimizers import Adam\n","import matplotlib.pyplot as plt\n"],"metadata":{"id":"2qgEV-gGiv3z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) = cifar10.load_data()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FOoWE5YYjELB","executionInfo":{"status":"ok","timestamp":1729220209964,"user_tz":240,"elapsed":59176,"user":{"displayName":"Rahul shah","userId":"08697968008726674087"}},"outputId":"a41da017-7b3f-4af4-dcbd-23283e4c2de4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 0us/step\n"]}]},{"cell_type":"markdown","source":["1. We are first normalizing the inputs, since the input is a range from (0 to 255), we normalise them from 0 to 1, this helps during converging as they converge faster and even scaling enables the network to learn patterns more efficiently \\\\\n","2. We then do one-hot encoding since we will be using categorical crossentropy as our loss function, since the problem is a multi-class classification and this requires that all the classes be one-hot encoded"],"metadata":{"id":"XgvEGyKWxv7Y"}},{"cell_type":"code","source":["x_train = x_train.astype('float32') / 255.0\n","x_test = x_test.astype('float32') / 255.0\n","\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n","num_classes = y_test.shape[1]\n","input_shape = x_train.shape[1:]\n"],"metadata":{"id":"PJacsOtBjwC0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_cnn(architecture):\n","    model = Sequential()\n","    added_flatten = False  # Track if a Flatten layer has been added\n","\n","    for layer in architecture:\n","        if layer['type'] == 'conv' and not added_flatten:\n","            # Add Conv2D layer only if Flatten has not been added\n","            model.add(Conv2D(layer['filters'], (3, 3), activation=layer['activation'], input_shape=input_shape))\n","            model.add(MaxPooling2D(pool_size=(2, 2)))\n","        elif layer['type'] == 'dense':\n","            if not added_flatten:\n","                # Add Flatten layer before adding dense layers\n","                model.add(Flatten())\n","                added_flatten = True\n","            model.add(Dense(layer['units'], activation=layer['activation']))\n","\n","    # Ensure the model has been flattened before adding the final dense layer\n","    if not added_flatten:\n","        model.add(Flatten())\n","\n","    # Add the final output layer\n","    model.add(Dense(num_classes, activation='softmax'))\n","\n","    # Compile the model\n","    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    return model\n","\n","\n","def evaluate_cnn(architecture):\n","    model = create_cnn(architecture)\n","    model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=32, verbose=0)\n","    score = model.evaluate(x_test, y_test, verbose=0)\n","    return score[1]  # Return accuracy as fitness\n"],"metadata":{"id":"tBptKgCykj9Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n","creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n","\n","def generate_individual():\n","    layers = []\n","    num_layers = random.randint(2, 5)  # Random number of layers\n","    for _ in range(num_layers):\n","        layer_type = random.choice(['conv', 'dense'])\n","        if layer_type == 'conv':\n","            layers.append({\n","                'type': 'conv',\n","                'filters': random.choice([16, 32, 64]),\n","                'activation': random.choice(['relu', 'tanh'])\n","            })\n","        elif layer_type == 'dense':\n","            layers.append({\n","                'type': 'dense',\n","                'units': random.choice([64, 128, 256]),\n","                'activation': random.choice(['relu', 'tanh'])\n","            })\n","    return layers\n","\n","toolbox = base.Toolbox()\n","toolbox.register(\"individual\", tools.initIterate, creator.Individual, generate_individual)\n","toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n","toolbox.register(\"evaluate\", evaluate_cnn)\n","toolbox.register(\"mate\", tools.cxTwoPoint)\n","toolbox.register(\"mutate\", tools.mutShuffleIndexes, indpb=0.2)\n","toolbox.register(\"select\", tools.selTournament, tournsize=3)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tj4m9DF3knho","executionInfo":{"status":"ok","timestamp":1729220798806,"user_tz":240,"elapsed":143,"user":{"displayName":"Rahul shah","userId":"08697968008726674087"}},"outputId":"4e6239c3-2067-4768-ecf8-54f9a19fbac9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n","  warnings.warn(\"A class named '{0}' has already been created and it \"\n","/usr/local/lib/python3.10/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n","  warnings.warn(\"A class named '{0}' has already been created and it \"\n"]}]},{"cell_type":"code","source":["def evolve_population():\n","    population = toolbox.population(n=10)  # Create a population of 10 individuals\n","    ngen = 5  # Number of generations\n","    cxpb = 0.5  # Crossover probability\n","    mutpb = 0.2  # Mutation probability\n","\n","    for gen in range(ngen):\n","        print(f\"-- Generation {gen} --\")\n","\n","        # Evaluate the entire population\n","        fitnesses = list(map(toolbox.evaluate, population))\n","        for ind, fit in zip(population, fitnesses):\n","            ind.fitness.values = (fit,)\n","\n","        # Select the next generation individuals\n","        offspring = toolbox.select(population, len(population))\n","\n","        # Clone the selected individuals\n","        offspring = list(map(toolbox.clone, offspring))\n","\n","        # Apply crossover and mutation on the offspring\n","        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n","            if random.random() < cxpb:\n","                toolbox.mate(child1, child2)\n","                del child1.fitness.values\n","                del child2.fitness.values\n","\n","        for mutant in offspring:\n","            if random.random() < mutpb:\n","                toolbox.mutate(mutant)\n","                del mutant.fitness.values\n","\n","        # Evaluate the new offspring\n","        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n","        fitnesses = map(toolbox.evaluate, invalid_ind)\n","        for ind, fit in zip(invalid_ind, fitnesses):\n","            ind.fitness.values = (fit,)\n","\n","        # Replace population with offspring\n","        population[:] = offspring\n","\n","    # Gather and return the best individual\n","    best_ind = tools.selBest(population, 1)[0]\n","    print(f\"Best individual: {best_ind}\")\n","    return best_ind\n"],"metadata":{"id":"lPUdBzsgkqde"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_architecture = evolve_population()\n","print(\"Best architecture found:\", best_architecture)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329},"id":"mkUUmeuXksir","executionInfo":{"status":"error","timestamp":1729220804978,"user_tz":240,"elapsed":3655,"user":{"displayName":"Rahul shah","userId":"08697968008726674087"}},"outputId":"ce443290-3298-4b8d-9d27-6cab70725457"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["-- Generation 0 --\n"]},{"output_type":"error","ename":"ValueError","evalue":"Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 10, 2), output.shape=(None, 10)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-61-4531e96eea86>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_architecture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevolve_population\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best architecture found:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_architecture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-60-380634b791d9>\u001b[0m in \u001b[0;36mevolve_population\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Evaluate the entire population\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mfitnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-58-fb4a01d18684>\u001b[0m in \u001b[0;36mevaluate_cnn\u001b[0;34m(architecture)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Return accuracy as fitness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    552\u001b[0m         )\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    555\u001b[0m             \u001b[0;34m\"Arguments `target` and `output` must have the same rank \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;34m\"(ndim). Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 10, 2), output.shape=(None, 10)"]}]},{"cell_type":"code","source":[],"metadata":{"id":"XMEgjvDLl3KH"},"execution_count":null,"outputs":[]}]}